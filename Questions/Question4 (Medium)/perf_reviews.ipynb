{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "2567df77",
   "metadata": {},
   "outputs": [],
   "source": [
    "import pyspark\n",
    "from pyspark.sql import SparkSession\n",
    "from pyspark.sql.functions import *\n",
    "from pyspark.sql import Window"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "18aa0a13",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "3.5.5\n"
     ]
    }
   ],
   "source": [
    "print(pyspark.__version__)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "ade9cfcd",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "25/05/04 17:00:22 WARN Utils: Your hostname, Ameys-Mac-mini.local resolves to a loopback address: 127.0.0.1; using 192.168.1.12 instead (on interface en1)\n",
      "25/05/04 17:00:22 WARN Utils: Set SPARK_LOCAL_IP if you need to bind to another address\n",
      "Setting default log level to \"WARN\".\n",
      "To adjust logging level use sc.setLogLevel(newLevel). For SparkR, use setLogLevel(newLevel).\n",
      "25/05/04 17:00:23 WARN NativeCodeLoader: Unable to load native-hadoop library for your platform... using builtin-java classes where applicable\n"
     ]
    }
   ],
   "source": [
    "spark = SparkSession.builder \\\n",
    "    .appName(\"Performance Reviews\") \\\n",
    "    .master(\"local[*]\") \\\n",
    "    .getOrCreate()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "166ed365",
   "metadata": {},
   "outputs": [],
   "source": [
    "employees_df = spark.read.csv(\"employees.csv\", header=True, inferSchema=True)\n",
    "performance_reviews_df = spark.read.csv(\"performance_reviews.csv\", header=True, inferSchema=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "a341a2e7",
   "metadata": {},
   "outputs": [],
   "source": [
    "employees_df.createOrReplaceTempView(\"employees\")\n",
    "performance_reviews_df.createOrReplaceTempView(\"performance_reviews\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "eb343a00",
   "metadata": {},
   "source": [
    "## Data Exploration"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "87176460",
   "metadata": {},
   "source": [
    "### Show the schema and 5 sample records from each DataFrame."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "4a8a6646",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "+-----------+----------------+----------+---------+----------+\n",
      "|employee_id|   employee_name|department| position| hire_date|\n",
      "+-----------+----------------+----------+---------+----------+\n",
      "|          1|Jennifer Estrada|     Sales|  Analyst|2022-11-05|\n",
      "|          2|    Tammy Jordan| Marketing|  Manager|2022-11-29|\n",
      "|          3|     Emily Walsh| Marketing|  Manager|2024-05-01|\n",
      "|          4|      Cindy Hall| Marketing|     Lead|2023-03-06|\n",
      "|          5|     Aaron Smith|     Sales|Associate|2021-06-21|\n",
      "+-----------+----------------+----------+---------+----------+\n",
      "only showing top 5 rows\n",
      "\n"
     ]
    }
   ],
   "source": [
    "employees_df.show(5)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "27598661",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "+---------+-----------+-----------+-----+\n",
      "|review_id|employee_id|review_date|score|\n",
      "+---------+-----------+-----------+-----+\n",
      "|        1|         33| 2024-10-20|    2|\n",
      "|        2|         38| 2025-04-20|    5|\n",
      "|        3|         29| 2023-06-09|    5|\n",
      "|        4|         13| 2023-12-29|    1|\n",
      "|        5|         27| 2023-12-10|    5|\n",
      "+---------+-----------+-----------+-----+\n",
      "only showing top 5 rows\n",
      "\n"
     ]
    }
   ],
   "source": [
    "performance_reviews_df.show(5)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "25b4ef4c",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "root\n",
      " |-- employee_id: integer (nullable = true)\n",
      " |-- employee_name: string (nullable = true)\n",
      " |-- department: string (nullable = true)\n",
      " |-- position: string (nullable = true)\n",
      " |-- hire_date: date (nullable = true)\n",
      "\n"
     ]
    }
   ],
   "source": [
    "employees_df.printSchema()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "f99c5bf2",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "root\n",
      " |-- review_id: integer (nullable = true)\n",
      " |-- employee_id: integer (nullable = true)\n",
      " |-- review_date: date (nullable = true)\n",
      " |-- score: integer (nullable = true)\n",
      "\n"
     ]
    }
   ],
   "source": [
    "performance_reviews_df.printSchema()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "72f9eb03",
   "metadata": {},
   "source": [
    "### How many performance reviews does each employee have?"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "a4e9bd20",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "+-----------+------------+\n",
      "|employee_id|review_count|\n",
      "+-----------+------------+\n",
      "|         27|           8|\n",
      "|          8|           7|\n",
      "|         29|           7|\n",
      "|         37|           6|\n",
      "|         21|           6|\n",
      "+-----------+------------+\n",
      "only showing top 5 rows\n",
      "\n"
     ]
    }
   ],
   "source": [
    "spark.sql(\n",
    "    \"\"\"\n",
    "    SELECT\n",
    "        e.employee_id,\n",
    "        count(r.employee_id) as review_count\n",
    "    FROM employees e\n",
    "    LEFT JOIN performance_reviews r\n",
    "    USING(employee_id)\n",
    "    GROUP BY 1\n",
    "    ORDER BY 2 DESC\n",
    "    \"\"\"\n",
    ").show(5)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "4484da70",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "+-----------+------------+\n",
      "|employee_id|review_count|\n",
      "+-----------+------------+\n",
      "|         27|           8|\n",
      "|          8|           7|\n",
      "|         29|           7|\n",
      "|         37|           6|\n",
      "|         21|           6|\n",
      "+-----------+------------+\n",
      "only showing top 5 rows\n",
      "\n"
     ]
    }
   ],
   "source": [
    "employees_df.join(\n",
    "    performance_reviews_df,\n",
    "    on=[\"employee_id\"],\n",
    "    how=\"left\"\n",
    ").groupBy(\"employee_id\") \\\n",
    "    .agg(count(\"employee_id\").alias(\"review_count\")) \\\n",
    "    .orderBy(desc(\"review_count\")) \\\n",
    "    .show(5)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "60a430b8",
   "metadata": {},
   "source": [
    "## Window Functions Practice"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "08afbaf4",
   "metadata": {},
   "source": [
    "### Assign a rank to each review based on the review_date within each employee."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "id": "4e595eb8",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "+-----------+-----------+-----+----+\n",
      "|employee_id|review_date|score|rank|\n",
      "+-----------+-----------+-----+----+\n",
      "|          1| 2024-10-08|    4|   1|\n",
      "|          1| 2024-07-01|    1|   2|\n",
      "|          1| 2023-12-07|    3|   3|\n",
      "|          2| 2024-07-12|    5|   1|\n",
      "|          2| 2023-12-26|    1|   2|\n",
      "+-----------+-----------+-----+----+\n",
      "only showing top 5 rows\n",
      "\n"
     ]
    }
   ],
   "source": [
    "spark.sql(\n",
    "    \"\"\"\n",
    "    SELECT\n",
    "        employee_id,\n",
    "        review_date,\n",
    "        score,\n",
    "        RANK() OVER (PARTITION BY employee_id ORDER BY review_date DESC) as rank\n",
    "    FROM performance_reviews\n",
    "    \"\"\"\n",
    ").show(5)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "id": "29f67c61",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "+-----------+-----------+-----+----+\n",
      "|employee_id|review_date|score|rank|\n",
      "+-----------+-----------+-----+----+\n",
      "|          1| 2024-10-08|    4|   1|\n",
      "|          1| 2024-07-01|    1|   2|\n",
      "|          1| 2023-12-07|    3|   3|\n",
      "|          2| 2024-07-12|    5|   1|\n",
      "|          2| 2023-12-26|    1|   2|\n",
      "+-----------+-----------+-----+----+\n",
      "only showing top 5 rows\n",
      "\n"
     ]
    }
   ],
   "source": [
    "window_spec = Window.partitionBy(\"employee_id\").orderBy(desc(\"review_date\"))\n",
    "performance_reviews_df.withColumn(\n",
    "    \"rank\",\n",
    "    rank().over(window_spec)\n",
    ").select(\n",
    "    \"employee_id\",\n",
    "    \"review_date\",\n",
    "    \"score\",\n",
    "    \"rank\"\n",
    ").show(5)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "70d3e951",
   "metadata": {},
   "source": [
    "### Assign a row number to each review ordered by review_date per employee."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "id": "ceeec2af",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "+-----------+-----------+-----+----------+\n",
      "|employee_id|review_date|score|row_number|\n",
      "+-----------+-----------+-----+----------+\n",
      "|          1| 2024-10-08|    4|         1|\n",
      "|          1| 2024-07-01|    1|         2|\n",
      "|          1| 2023-12-07|    3|         3|\n",
      "|          2| 2024-07-12|    5|         1|\n",
      "|          2| 2023-12-26|    1|         2|\n",
      "+-----------+-----------+-----+----------+\n",
      "only showing top 5 rows\n",
      "\n"
     ]
    }
   ],
   "source": [
    "spark.sql(\n",
    "    \"\"\"\n",
    "    SELECT\n",
    "        employee_id,\n",
    "        review_date,\n",
    "        score,\n",
    "        ROW_NUMBER() OVER (PARTITION BY employee_id ORDER BY review_date DESC) as row_number\n",
    "    FROM performance_reviews\n",
    "    \"\"\"\n",
    ").show(5)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "id": "27bf9032",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "+-----------+-----------+-----+----------+\n",
      "|employee_id|review_date|score|row_number|\n",
      "+-----------+-----------+-----+----------+\n",
      "|          1| 2024-10-08|    4|         1|\n",
      "|          1| 2024-07-01|    1|         2|\n",
      "|          1| 2023-12-07|    3|         3|\n",
      "|          2| 2024-07-12|    5|         1|\n",
      "|          2| 2023-12-26|    1|         2|\n",
      "+-----------+-----------+-----+----------+\n",
      "only showing top 5 rows\n",
      "\n"
     ]
    }
   ],
   "source": [
    "window_spec = Window.partitionBy(\"employee_id\").orderBy(desc(\"review_date\"))\n",
    "performance_reviews_df.withColumn(\n",
    "    \"row_number\",\n",
    "    row_number().over(window_spec)\n",
    ").select(\n",
    "    \"employee_id\",\n",
    "    \"review_date\",\n",
    "    \"score\",\n",
    "    \"row_number\"\n",
    ").show(5)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "e489ccfc",
   "metadata": {},
   "source": [
    "### Use a window function to calculate the average score for each employee across all reviews."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "id": "5fd56c76",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "+-----------+-----------+-----+---------+\n",
      "|employee_id|review_date|score|avg_score|\n",
      "+-----------+-----------+-----+---------+\n",
      "|          1| 2023-12-07|    3|     2.67|\n",
      "|          1| 2024-07-01|    1|     2.67|\n",
      "|          1| 2024-10-08|    4|     2.67|\n",
      "|          2| 2023-12-26|    1|      3.0|\n",
      "|          2| 2024-07-12|    5|      3.0|\n",
      "+-----------+-----------+-----+---------+\n",
      "only showing top 5 rows\n",
      "\n"
     ]
    }
   ],
   "source": [
    "spark.sql(\n",
    "    \"\"\"\n",
    "    SELECT\n",
    "        employee_id,\n",
    "        review_date,\n",
    "        score,\n",
    "        ROUND(AVG(score) OVER (PARTITION BY employee_id), 2) as avg_score\n",
    "    FROM performance_reviews\n",
    "    \"\"\"\n",
    ").show(5)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "id": "aaddae4a",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "+-----------+-----------+-----+---------+\n",
      "|employee_id|review_date|score|avg_score|\n",
      "+-----------+-----------+-----+---------+\n",
      "|          1| 2023-12-07|    3|     2.67|\n",
      "|          1| 2024-07-01|    1|     2.67|\n",
      "|          1| 2024-10-08|    4|     2.67|\n",
      "|          2| 2023-12-26|    1|      3.0|\n",
      "|          2| 2024-07-12|    5|      3.0|\n",
      "+-----------+-----------+-----+---------+\n",
      "only showing top 5 rows\n",
      "\n"
     ]
    }
   ],
   "source": [
    "window_spec = Window.partitionBy(\"employee_id\")\n",
    "performance_reviews_df.withColumn(\n",
    "    \"avg_score\",\n",
    "    round(avg(\"score\").over(window_spec), 2)\n",
    ").select(\n",
    "    \"employee_id\",\n",
    "    \"review_date\",\n",
    "    \"score\",\n",
    "    \"avg_score\"\n",
    ").show(5)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "8703258e",
   "metadata": {},
   "source": [
    "### Find the difference between each review's score and the employee’s average score using window functions."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "id": "fb691ada",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "+-----------+-----------+-----+---------+----------+\n",
      "|employee_id|review_date|score|avg_score|score_diff|\n",
      "+-----------+-----------+-----+---------+----------+\n",
      "|          1| 2023-12-07|    3|     2.67|      0.33|\n",
      "|          1| 2024-07-01|    1|     2.67|     -1.67|\n",
      "|          1| 2024-10-08|    4|     2.67|      1.33|\n",
      "|          2| 2023-12-26|    1|      3.0|      -2.0|\n",
      "|          2| 2024-07-12|    5|      3.0|       2.0|\n",
      "+-----------+-----------+-----+---------+----------+\n",
      "only showing top 5 rows\n",
      "\n"
     ]
    }
   ],
   "source": [
    "spark.sql(\n",
    "    \"\"\"\n",
    "    SELECT\n",
    "        employee_id,\n",
    "        review_date,\n",
    "        score,\n",
    "        round(AVG(score) OVER (PARTITION BY employee_id), 2) as avg_score,\n",
    "        round(score - AVG (score) OVER (PARTITION BY employee_id), 2) as score_diff\n",
    "    FROM performance_reviews\n",
    "    \"\"\"\n",
    ").show(5)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "id": "8aca5f89",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "+-----------+-----------+-----+---------+----------+\n",
      "|employee_id|review_date|score|avg_score|score_diff|\n",
      "+-----------+-----------+-----+---------+----------+\n",
      "|          1| 2023-12-07|    3|     2.67|      0.33|\n",
      "|          1| 2024-07-01|    1|     2.67|     -1.67|\n",
      "|          1| 2024-10-08|    4|     2.67|      1.33|\n",
      "|          2| 2023-12-26|    1|      3.0|      -2.0|\n",
      "|          2| 2024-07-12|    5|      3.0|       2.0|\n",
      "+-----------+-----------+-----+---------+----------+\n",
      "only showing top 5 rows\n",
      "\n"
     ]
    }
   ],
   "source": [
    "window_spec = Window.partitionBy(\"employee_id\")\n",
    "performance_reviews_df.withColumn(\n",
    "    \"avg_score\",\n",
    "    round(avg(\"score\").over(window_spec), 2)\n",
    ").withColumn(\n",
    "    \"score_diff\",\n",
    "    round(col(\"score\") - avg(\"score\").over(window_spec), 2)\n",
    ").select(\n",
    "    \"employee_id\",\n",
    "    \"review_date\",\n",
    "    \"score\",\n",
    "    \"avg_score\",\n",
    "    \"score_diff\"\n",
    ").show(5)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "08471017",
   "metadata": {},
   "source": [
    "### Use LAG to get the previous review's score per employee and calculate the change in score."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "id": "3abe9242",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "+-----------+-----------+-----+--------------+------------+\n",
      "|employee_id|review_date|score|previous_score|score_change|\n",
      "+-----------+-----------+-----+--------------+------------+\n",
      "|          1| 2023-12-07|    3|          NULL|        NULL|\n",
      "|          1| 2024-07-01|    1|             3|          -2|\n",
      "|          1| 2024-10-08|    4|             1|           3|\n",
      "|          2| 2023-12-26|    1|          NULL|        NULL|\n",
      "|          2| 2024-07-12|    5|             1|           4|\n",
      "+-----------+-----------+-----+--------------+------------+\n",
      "only showing top 5 rows\n",
      "\n"
     ]
    }
   ],
   "source": [
    "spark.sql(\n",
    "    \"\"\"\n",
    "    SELECT\n",
    "        employee_id,\n",
    "        review_date,\n",
    "        score,\n",
    "        LAG(score) OVER (PARTITION BY employee_id ORDER BY review_date) as previous_score,\n",
    "        score - LAG(score) OVER (PARTITION BY employee_id ORDER BY review_date) as score_change\n",
    "    FROM performance_reviews\n",
    "    \"\"\"\n",
    ").show(5)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "id": "ec8d1cbb",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "+-----------+-----------+-----+--------------+------------+\n",
      "|employee_id|review_date|score|previous_score|score_change|\n",
      "+-----------+-----------+-----+--------------+------------+\n",
      "|          1| 2023-12-07|    3|          NULL|        NULL|\n",
      "|          1| 2024-07-01|    1|             3|          -2|\n",
      "|          1| 2024-10-08|    4|             1|           3|\n",
      "|          2| 2023-12-26|    1|          NULL|        NULL|\n",
      "|          2| 2024-07-12|    5|             1|           4|\n",
      "+-----------+-----------+-----+--------------+------------+\n",
      "only showing top 5 rows\n",
      "\n"
     ]
    }
   ],
   "source": [
    "window_spec = Window.partitionBy(\"employee_id\").orderBy(\"review_date\")\n",
    "performance_reviews_df.withColumn(\n",
    "    \"previous_score\",\n",
    "    lag(\"score\", 1).over(window_spec)\n",
    ").withColumn(\n",
    "    \"score_change\",\n",
    "    col(\"score\") - lag(\"score\", 1).over(window_spec)\n",
    ").select(\n",
    "    \"employee_id\",\n",
    "    \"review_date\",\n",
    "    \"score\",\n",
    "    \"previous_score\",\n",
    "    \"score_change\"\n",
    ").show(5)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "d89e66d9",
   "metadata": {},
   "source": [
    "### Use LEAD to compare each review's score to the next one per employee."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "id": "d7f46076",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "+-----------+-----------+-----+----------+\n",
      "|employee_id|review_date|score|next_score|\n",
      "+-----------+-----------+-----+----------+\n",
      "|          1| 2023-12-07|    3|         1|\n",
      "|          1| 2024-07-01|    1|         4|\n",
      "|          1| 2024-10-08|    4|      NULL|\n",
      "|          2| 2023-12-26|    1|         5|\n",
      "|          2| 2024-07-12|    5|      NULL|\n",
      "+-----------+-----------+-----+----------+\n",
      "only showing top 5 rows\n",
      "\n"
     ]
    }
   ],
   "source": [
    "spark.sql(\n",
    "    \"\"\"\n",
    "    SELECT\n",
    "        employee_id,\n",
    "        review_date,\n",
    "        score,\n",
    "        LEAD(score) OVER (PARTITION BY employee_id ORDER BY review_date) as next_score\n",
    "    FROM performance_reviews\n",
    "    \"\"\"\n",
    ").show(5)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "id": "40b6dfed",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "+-----------+-----------+-----+----------+\n",
      "|employee_id|review_date|score|next_score|\n",
      "+-----------+-----------+-----+----------+\n",
      "|          1| 2023-12-07|    3|         1|\n",
      "|          1| 2024-07-01|    1|         4|\n",
      "|          1| 2024-10-08|    4|      NULL|\n",
      "|          2| 2023-12-26|    1|         5|\n",
      "|          2| 2024-07-12|    5|      NULL|\n",
      "+-----------+-----------+-----+----------+\n",
      "only showing top 5 rows\n",
      "\n"
     ]
    }
   ],
   "source": [
    "window_spec = Window.partitionBy(\"employee_id\").orderBy(\"review_date\")\n",
    "performance_reviews_df.withColumn(\n",
    "    \"next_score\",\n",
    "    lead(\"score\", 1).over(window_spec)\n",
    ").select(\n",
    "    \"employee_id\",\n",
    "    \"review_date\",\n",
    "    \"score\",\n",
    "    \"next_score\"\n",
    ").show(5)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "ebd1faea",
   "metadata": {},
   "source": [
    "### Get the most recent review per employee using ROW_NUMBER."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 35,
   "id": "6b1a9c8d",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "+-----------+----------------+------------------+------------+\n",
      "|employee_id|   employee_name|latest_review_date|latest_score|\n",
      "+-----------+----------------+------------------+------------+\n",
      "|          1|Jennifer Estrada|        2024-10-08|           4|\n",
      "|          2|    Tammy Jordan|        2024-07-12|           5|\n",
      "|          3|     Emily Walsh|        2024-03-02|           2|\n",
      "|          4|      Cindy Hall|        2023-05-05|           2|\n",
      "|          5|     Aaron Smith|        2023-10-10|           4|\n",
      "+-----------+----------------+------------------+------------+\n",
      "only showing top 5 rows\n",
      "\n"
     ]
    }
   ],
   "source": [
    "spark.sql(\n",
    "    \"\"\"\n",
    "    with cte as (\n",
    "        SELECT\n",
    "            employee_id,\n",
    "            score,\n",
    "            review_date,\n",
    "            ROW_NUMBER() OVER (PARTITION BY employee_id ORDER BY review_date DESC) as row_number\n",
    "        FROM performance_reviews\n",
    "    )\n",
    "    \n",
    "    SELECT \n",
    "        c.employee_id,\n",
    "        e.employee_name,\n",
    "        c.review_date as latest_review_date,\n",
    "        c.score as latest_score \n",
    "    FROM cte c\n",
    "    JOIN employees e\n",
    "    USING(employee_id)\n",
    "    WHERE row_number = 1\n",
    "    \"\"\"\n",
    ").show(5)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 38,
   "id": "dc68d46f",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "+-----------+----------------+------------------+-------------------+\n",
      "|employee_id|   employee_name|latest_review_date|latest_review_score|\n",
      "+-----------+----------------+------------------+-------------------+\n",
      "|          1|Jennifer Estrada|        2024-10-08|                  4|\n",
      "|          2|    Tammy Jordan|        2024-07-12|                  5|\n",
      "|          3|     Emily Walsh|        2024-03-02|                  2|\n",
      "|          4|      Cindy Hall|        2023-05-05|                  2|\n",
      "|          5|     Aaron Smith|        2023-10-10|                  4|\n",
      "+-----------+----------------+------------------+-------------------+\n",
      "only showing top 5 rows\n",
      "\n"
     ]
    }
   ],
   "source": [
    "window_spec = Window.partitionBy(\"employee_id\").orderBy(desc(\"review_date\"))\n",
    "\n",
    "windowed_df = performance_reviews_df.withColumn(\n",
    "    \"row_number\",\n",
    "    row_number().over(window_spec)\n",
    ")\n",
    "\n",
    "filtered_df = windowed_df.filter(\n",
    "    col(\"row_number\") == 1\n",
    ")\n",
    "\n",
    "employees_df.join(\n",
    "    filtered_df,\n",
    "    on=[\"employee_id\"],\n",
    "    how=\"inner\"\n",
    ").select(\n",
    "    \"employee_id\",\n",
    "    \"employee_name\",\n",
    "    filtered_df[\"review_date\"].alias(\"latest_review_date\"),\n",
    "    filtered_df[\"score\"].alias(\"latest_review_score\")\n",
    ").show(5)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "3149ddc6",
   "metadata": {},
   "source": [
    "### Calculate a rolling average score over the last 3 reviews per employee."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 41,
   "id": "5a16deab",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "+-----------+-----------+-----+-----------+\n",
      "|employee_id|review_date|score|rolling_avg|\n",
      "+-----------+-----------+-----+-----------+\n",
      "|          1| 2023-12-07|    3|        3.0|\n",
      "|          1| 2024-07-01|    1|        2.0|\n",
      "|          1| 2024-10-08|    4|       2.67|\n",
      "|          2| 2023-12-26|    1|        1.0|\n",
      "|          2| 2024-07-12|    5|        3.0|\n",
      "|          3| 2023-11-24|    4|        4.0|\n",
      "|          3| 2024-01-26|    5|        4.5|\n",
      "|          3| 2024-03-02|    2|       3.67|\n",
      "|          4| 2023-05-05|    2|        2.0|\n",
      "|          5| 2023-10-10|    4|        4.0|\n",
      "|          6| 2023-06-24|    2|        2.0|\n",
      "|          6| 2023-11-15|    3|        2.5|\n",
      "|          6| 2024-12-20|    1|        2.0|\n",
      "|          7| 2023-10-27|    2|        2.0|\n",
      "|          7| 2024-05-22|    4|        3.0|\n",
      "|          7| 2025-01-08|    3|        3.0|\n",
      "|          8| 2023-06-18|    5|        5.0|\n",
      "|          8| 2023-10-01|    4|        4.5|\n",
      "|          8| 2024-02-10|    2|       3.67|\n",
      "|          8| 2024-05-30|    1|       2.33|\n",
      "+-----------+-----------+-----+-----------+\n",
      "only showing top 20 rows\n",
      "\n"
     ]
    }
   ],
   "source": [
    "spark.sql(\n",
    "    \"\"\"\n",
    "    SELECT\n",
    "        employee_id,\n",
    "        review_date,\n",
    "        score,\n",
    "        ROUND(AVG(score) OVER (\n",
    "            PARTITION BY employee_id \n",
    "            ORDER BY review_date \n",
    "            ROWS BETWEEN 2 PRECEDING AND CURRENT ROW\n",
    "        ), 2) as rolling_avg\n",
    "    FROM performance_reviews\n",
    "    \"\"\"\n",
    ").show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 42,
   "id": "dd482c32",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "+-----------+-----------+-----+-----------+\n",
      "|employee_id|review_date|score|rolling_avg|\n",
      "+-----------+-----------+-----+-----------+\n",
      "|          1| 2023-12-07|    3|        3.0|\n",
      "|          1| 2024-07-01|    1|        2.0|\n",
      "|          1| 2024-10-08|    4|       2.67|\n",
      "|          2| 2023-12-26|    1|        1.0|\n",
      "|          2| 2024-07-12|    5|        3.0|\n",
      "+-----------+-----------+-----+-----------+\n",
      "only showing top 5 rows\n",
      "\n"
     ]
    }
   ],
   "source": [
    "window_spec = Window.partitionBy(\"employee_id\").orderBy(\"review_date\").rowsBetween(-2, 0)\n",
    "\n",
    "performance_reviews_df.withColumn(\n",
    "    \"rolling_avg\",\n",
    "    round(avg(\"score\").over(window_spec), 2)\n",
    ").select(\n",
    "    \"employee_id\",\n",
    "    \"review_date\",\n",
    "    \"score\",\n",
    "    \"rolling_avg\"\n",
    ").show(5)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "80a4d430",
   "metadata": {},
   "source": [
    "### For each department, rank employees based on their latest review score (highest to lowest)."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 44,
   "id": "affd84dd",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "+-----------+-----------+-----+----+\n",
      "| department|employee_id|score|rank|\n",
      "+-----------+-----------+-----+----+\n",
      "|Engineering|         38|    5|   1|\n",
      "|Engineering|         25|    4|   2|\n",
      "|Engineering|          9|    3|   3|\n",
      "|Engineering|         24|    3|   3|\n",
      "|Engineering|         11|    2|   5|\n",
      "|Engineering|         29|    2|   5|\n",
      "|Engineering|         30|    2|   5|\n",
      "|Engineering|         31|    2|   5|\n",
      "|Engineering|          6|    1|   9|\n",
      "|Engineering|         19|    1|   9|\n",
      "|    Finance|         33|    4|   1|\n",
      "|    Finance|         27|    2|   2|\n",
      "|    Finance|          8|    1|   3|\n",
      "|         HR|         17|    5|   1|\n",
      "|         HR|         26|    5|   1|\n",
      "|         HR|         37|    4|   3|\n",
      "|         HR|          7|    3|   4|\n",
      "|         HR|         16|    3|   4|\n",
      "|         HR|         39|    3|   4|\n",
      "|         HR|         13|    1|   7|\n",
      "+-----------+-----------+-----+----+\n",
      "only showing top 20 rows\n",
      "\n"
     ]
    }
   ],
   "source": [
    "spark.sql(\n",
    "    \"\"\"\n",
    "    with cte as (\n",
    "        SELECT\n",
    "            e.department,\n",
    "            e.employee_id,\n",
    "            r.score,\n",
    "            ROW_NUMBER() OVER (PARTITION BY employee_id ORDER BY review_date DESC) as latest_review\n",
    "        FROM employees e\n",
    "        JOIN performance_reviews r\n",
    "        USING(employee_id)\n",
    "    )\n",
    "    SELECT\n",
    "        department,\n",
    "        employee_id,\n",
    "        score,\n",
    "        RANK() OVER (PARTITION BY department ORDER BY score DESC) as rank\n",
    "    FROM cte\n",
    "    WHERE latest_review = 1\n",
    "    \"\"\"\n",
    ").show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "85946530",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "+-----------+-----------+-----+----+\n",
      "| department|employee_id|score|rank|\n",
      "+-----------+-----------+-----+----+\n",
      "|Engineering|         38|    5|   1|\n",
      "|Engineering|         25|    4|   2|\n",
      "|Engineering|          9|    3|   3|\n",
      "|Engineering|         24|    3|   3|\n",
      "|Engineering|         11|    2|   5|\n",
      "|Engineering|         29|    2|   5|\n",
      "|Engineering|         30|    2|   5|\n",
      "|Engineering|         31|    2|   5|\n",
      "|Engineering|          6|    1|   9|\n",
      "|Engineering|         19|    1|   9|\n",
      "|    Finance|         33|    4|   1|\n",
      "|    Finance|         27|    2|   2|\n",
      "|    Finance|          8|    1|   3|\n",
      "|         HR|         17|    5|   1|\n",
      "|         HR|         26|    5|   1|\n",
      "|         HR|         37|    4|   3|\n",
      "|         HR|          7|    3|   4|\n",
      "|         HR|         16|    3|   4|\n",
      "|         HR|         39|    3|   4|\n",
      "|         HR|         13|    1|   7|\n",
      "+-----------+-----------+-----+----+\n",
      "only showing top 20 rows\n",
      "\n"
     ]
    }
   ],
   "source": [
    "window_spec_1 = Window.partitionBy(\"employee_id\").orderBy(desc(\"review_date\"))\n",
    "latest_reviews_df = performance_reviews_df.withColumn(\n",
    "    \"latest_review\",\n",
    "    row_number().over(window_spec_1)\n",
    ").filter(col(\"latest_review\") == 1)\n",
    "\n",
    "joined_df = latest_reviews_df.join(\n",
    "    employees_df, \n",
    "    on=\"employee_id\", \n",
    "    how=\"inner\"\n",
    ")\n",
    "\n",
    "window_spec_2 = Window.partitionBy(\"department\").orderBy(desc(\"score\"))\n",
    "final_df = joined_df.withColumn(\n",
    "    \"rank\", \n",
    "    rank().over(window_spec_2)\n",
    ")\n",
    "\n",
    "final_df.select(\n",
    "    \"department\", \n",
    "    \"employee_id\", \n",
    "    \"score\", \n",
    "    \"rank\"\n",
    ").show()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "bd44257a",
   "metadata": {},
   "source": [
    "### Use a window function to get cumulative review score per employee."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 48,
   "id": "c50830d8",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "+-----------+-----------+-----+----------------+\n",
      "|employee_id|review_date|score|cumulative_score|\n",
      "+-----------+-----------+-----+----------------+\n",
      "|          1| 2023-12-07|    3|               8|\n",
      "|          1| 2024-07-01|    1|               8|\n",
      "|          1| 2024-10-08|    4|               8|\n",
      "|          2| 2023-12-26|    1|               6|\n",
      "|          2| 2024-07-12|    5|               6|\n",
      "+-----------+-----------+-----+----------------+\n",
      "only showing top 5 rows\n",
      "\n"
     ]
    }
   ],
   "source": [
    "spark.sql(\n",
    "    \"\"\"\n",
    "    SELECT\n",
    "        employee_id,\n",
    "        review_date,\n",
    "        score,\n",
    "        SUM(score) OVER (PARTITION BY employee_id) as cumulative_score\n",
    "    FROM performance_reviews\n",
    "    \"\"\"\n",
    ").show(5)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 49,
   "id": "0851f562",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "+-----------+-----------+-----+----------------+\n",
      "|employee_id|review_date|score|cumulative_score|\n",
      "+-----------+-----------+-----+----------------+\n",
      "|          1| 2023-12-07|    3|               8|\n",
      "|          1| 2024-07-01|    1|               8|\n",
      "|          1| 2024-10-08|    4|               8|\n",
      "|          2| 2023-12-26|    1|               6|\n",
      "|          2| 2024-07-12|    5|               6|\n",
      "+-----------+-----------+-----+----------------+\n",
      "only showing top 5 rows\n",
      "\n"
     ]
    }
   ],
   "source": [
    "window_spec = Window.partitionBy(\"employee_id\")\n",
    "performance_reviews_df.withColumn(\n",
    "    \"cumulative_score\",\n",
    "    sum(\"score\").over(window_spec)\n",
    ").select(\n",
    "    \"employee_id\",\n",
    "    \"review_date\",\n",
    "    \"score\",\n",
    "    \"cumulative_score\"\n",
    ").show(5)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "3622309d",
   "metadata": {},
   "source": [
    "### For each employee, calculate the number of days between each review and the previous one."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 53,
   "id": "1effc713",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "+-----------+-----------+-------------+------------+\n",
      "|employee_id|review_date|previous_date|days_between|\n",
      "+-----------+-----------+-------------+------------+\n",
      "|          1| 2023-12-07|         NULL|        NULL|\n",
      "|          1| 2024-07-01|   2023-12-07|         207|\n",
      "|          1| 2024-10-08|   2024-07-01|          99|\n",
      "|          2| 2023-12-26|         NULL|        NULL|\n",
      "|          2| 2024-07-12|   2023-12-26|         199|\n",
      "+-----------+-----------+-------------+------------+\n",
      "only showing top 5 rows\n",
      "\n"
     ]
    }
   ],
   "source": [
    "spark.sql(\n",
    "    \"\"\"\n",
    "    SELECT\n",
    "        employee_id,\n",
    "        review_date,\n",
    "        LAG(review_date) OVER (PARTITION BY employee_id ORDER BY review_date) as previous_date,\n",
    "        DATEDIFF(review_date, LAG(review_date) OVER (PARTITION BY employee_id ORDER BY review_date)) as days_between\n",
    "    FROM performance_reviews\n",
    "    \"\"\"\n",
    ").show(5)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 54,
   "id": "fde661c2",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "+-----------+-----------+-------------+------------+\n",
      "|employee_id|review_date|previous_date|days_between|\n",
      "+-----------+-----------+-------------+------------+\n",
      "|          1| 2023-12-07|         NULL|        NULL|\n",
      "|          1| 2024-07-01|   2023-12-07|         207|\n",
      "|          1| 2024-10-08|   2024-07-01|          99|\n",
      "|          2| 2023-12-26|         NULL|        NULL|\n",
      "|          2| 2024-07-12|   2023-12-26|         199|\n",
      "+-----------+-----------+-------------+------------+\n",
      "only showing top 5 rows\n",
      "\n"
     ]
    }
   ],
   "source": [
    "window_spec = Window.partitionBy(\"employee_id\").orderBy('review_date')\n",
    "performance_reviews_df.withColumn(\n",
    "    \"previous_date\",\n",
    "    lag(\"review_date\", 1).over(window_spec)\n",
    ").withColumn(\n",
    "    \"days_between\",\n",
    "    datediff(col(\"review_date\"), lag(\"review_date\", 1).over(window_spec))\n",
    ").select(\n",
    "    \"employee_id\",\n",
    "    \"review_date\",\n",
    "    \"previous_date\",\n",
    "    \"days_between\"\n",
    ").show(5)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "venv",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.6"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}

{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "e59f556b",
   "metadata": {},
   "outputs": [],
   "source": [
    "import pyspark\n",
    "from pyspark.sql.functions import *"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "259cc061",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "3.5.5\n"
     ]
    }
   ],
   "source": [
    "print(pyspark.__version__)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "bd3ad081",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "25/05/04 18:30:17 WARN Utils: Your hostname, Ameys-Mac-mini.local resolves to a loopback address: 127.0.0.1; using 192.168.1.12 instead (on interface en1)\n",
      "25/05/04 18:30:17 WARN Utils: Set SPARK_LOCAL_IP if you need to bind to another address\n",
      "Setting default log level to \"WARN\".\n",
      "To adjust logging level use sc.setLogLevel(newLevel). For SparkR, use setLogLevel(newLevel).\n",
      "25/05/04 18:30:17 WARN NativeCodeLoader: Unable to load native-hadoop library for your platform... using builtin-java classes where applicable\n",
      "25/05/04 18:30:18 WARN Utils: Service 'SparkUI' could not bind on port 4040. Attempting port 4041.\n"
     ]
    }
   ],
   "source": [
    "from pyspark.sql import SparkSession\n",
    "\n",
    "spark = SparkSession.builder \\\n",
    "        .appName(\"Retail_Analysis\") \\\n",
    "        .master(\"local[*]\") \\\n",
    "        .getOrCreate()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "680a5ded",
   "metadata": {},
   "outputs": [],
   "source": [
    "df = spark.read.csv(\"retail_sales_data_easy.csv\", inferSchema=True, header=True)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "9f49667c",
   "metadata": {},
   "source": [
    "## Data Exploration and Cleaning"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "c6cc1723",
   "metadata": {},
   "source": [
    "### Print the schema and show the first 5 rows"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "ec6e6e50",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "+--------------------+-----------+------------------+----------------+---------------+--------+--------------+-------------+\n",
      "|      transaction_id|customer_id|     customer_name|product_category|purchase_amount|quantity|payment_method|purchase_date|\n",
      "+--------------------+-----------+------------------+----------------+---------------+--------+--------------+-------------+\n",
      "|1f5324d6-2a86-434...|       8028|      Kevin Rogers|        Clothing|         369.64|       4|          Cash|   2024-01-21|\n",
      "|60326ab1-d515-40c...|       5037|     Richard Arias|            Toys|          14.41|       4|   Credit Card|   2023-03-30|\n",
      "|db2bd023-03a8-4d4...|       3784|     Gilbert Reese|           Books|         367.36|       1|     Gift Card|   2023-07-10|\n",
      "|4977751b-8726-4d0...|       1386|     Jason Wallace|        Clothing|         404.03|       1|   Credit Card|   2023-12-15|\n",
      "|5143a0c9-8354-4f8...|       8837|        Karen Rich|  Home & Kitchen|         378.51|       5|        PayPal|   2024-10-28|\n",
      "|3ae6dec4-b804-4b3...|       4213|    Douglas Robles|            Toys|         468.24|       1|    Debit Card|   2024-12-12|\n",
      "|3962d410-224a-4de...|       4838|       David Davis|            Toys|          10.25|       5|        PayPal|   2023-08-25|\n",
      "|d320c14d-db57-484...|       6997|        John Combs|            Toys|         182.85|       5|        PayPal|   2022-11-16|\n",
      "|27244395-8732-485...|       9158|       Zoe Hawkins|            Toys|         452.45|       1|   Credit Card|   2023-01-06|\n",
      "|2d60b2ce-677b-44f...|       9476|        Eric Lewis|            Toys|         382.72|       4|     Gift Card|   2024-08-26|\n",
      "|911355fb-a80a-4d0...|       8899|     Daniel Nelson|     Electronics|         199.71|       4|     Gift Card|   2023-03-16|\n",
      "|6dd30d52-584f-4da...|       1785|Christopher Norman|        Clothing|         180.83|       1|    Debit Card|   2023-01-20|\n",
      "|9d6ddb97-d02f-485...|       4431|       Anna Sparks|            Toys|          404.7|       3|     Gift Card|   2022-11-21|\n",
      "|373fc0ab-a28f-466...|       1626|  Tyler Bernard MD|            Toys|         408.79|       4|     Gift Card|   2024-07-23|\n",
      "|d573c5e4-3e78-4ec...|       2448|     Anna Williams|        Clothing|          377.3|       3|    Debit Card|   2022-10-10|\n",
      "|e4b8f9cf-9fba-459...|       9830|     Douglas Perry|           Books|         284.48|       1|        PayPal|   2022-06-30|\n",
      "|7ae58ef1-8c35-421...|       5420|       Marc Wagner|        Clothing|           49.9|       4|     Gift Card|   2023-02-12|\n",
      "|a2a4c650-1463-471...|       4173|     Jason Flowers|  Home & Kitchen|         296.97|       3|   Credit Card|   2022-05-20|\n",
      "|524a7828-ece3-4ce...|       2680|  Reginald Patrick|        Clothing|         358.28|       3|   Credit Card|   2024-08-23|\n",
      "|4c0c22df-e633-4a7...|       3916|      Jeremy Davis|        Clothing|         377.15|       3|          Cash|   2024-02-23|\n",
      "+--------------------+-----------+------------------+----------------+---------------+--------+--------------+-------------+\n",
      "only showing top 20 rows\n",
      "\n"
     ]
    }
   ],
   "source": [
    "df.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "9d7d5492",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "+--------------------+-----------+-------------+----------------+---------------+--------+--------------+-------------+\n",
      "|      transaction_id|customer_id|customer_name|product_category|purchase_amount|quantity|payment_method|purchase_date|\n",
      "+--------------------+-----------+-------------+----------------+---------------+--------+--------------+-------------+\n",
      "|1f5324d6-2a86-434...|       8028| Kevin Rogers|        Clothing|         369.64|       4|          Cash|   2024-01-21|\n",
      "|60326ab1-d515-40c...|       5037|Richard Arias|            Toys|          14.41|       4|   Credit Card|   2023-03-30|\n",
      "|db2bd023-03a8-4d4...|       3784|Gilbert Reese|           Books|         367.36|       1|     Gift Card|   2023-07-10|\n",
      "|4977751b-8726-4d0...|       1386|Jason Wallace|        Clothing|         404.03|       1|   Credit Card|   2023-12-15|\n",
      "|5143a0c9-8354-4f8...|       8837|   Karen Rich|  Home & Kitchen|         378.51|       5|        PayPal|   2024-10-28|\n",
      "+--------------------+-----------+-------------+----------------+---------------+--------+--------------+-------------+\n",
      "only showing top 5 rows\n",
      "\n"
     ]
    }
   ],
   "source": [
    "df.show(5)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "1a166029",
   "metadata": {},
   "source": [
    "### Count the number of distinct customers"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "62ea0e4b",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "58"
      ]
     },
     "execution_count": 7,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df.select(\"customer_id\").distinct().count()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "81497971",
   "metadata": {},
   "source": [
    "### Find the number of nulls in each columns"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "262fcf3b",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "+--------------+-----------+-------------+----------------+---------------+--------+--------------+-------------+\n",
      "|transaction_id|customer_id|customer_name|product_category|purchase_amount|quantity|payment_method|purchase_date|\n",
      "+--------------+-----------+-------------+----------------+---------------+--------+--------------+-------------+\n",
      "|             0|          0|            0|               0|              0|       0|             0|            0|\n",
      "+--------------+-----------+-------------+----------------+---------------+--------+--------------+-------------+\n",
      "\n"
     ]
    }
   ],
   "source": [
    "nulls = df.select([sum(col(c).isNull().cast(\"int\")).alias(c) for c in df.columns])\n",
    "nulls.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "fdd1473a",
   "metadata": {},
   "source": [
    "### Get the count of transactions per product category"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "08b7695d",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "+----------------+----------------------+\n",
      "|product_category|number of transactions|\n",
      "+----------------+----------------------+\n",
      "|  Home & Kitchen|                     8|\n",
      "|     Electronics|                    12|\n",
      "|        Clothing|                    12|\n",
      "|           Books|                    11|\n",
      "|            Toys|                    17|\n",
      "+----------------+----------------------+\n",
      "\n"
     ]
    }
   ],
   "source": [
    "df.groupBy(\"product_category\") \\\n",
    "    .count() \\\n",
    "    .withColumnRenamed(\"count\", \"number of transactions\") \\\n",
    "    .show()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "35b619af",
   "metadata": {},
   "source": [
    "### What is the range of purchase dates?"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "f16eb5f7",
   "metadata": {},
   "outputs": [],
   "source": [
    "df.createOrReplaceTempView(\"retail_sales\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "b769073a",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "+-------------------+------------------+\n",
      "|first_purchase_date|last_purchase_date|\n",
      "+-------------------+------------------+\n",
      "|         2022-05-15|        2025-04-25|\n",
      "+-------------------+------------------+\n",
      "\n"
     ]
    }
   ],
   "source": [
    "spark.sql(\n",
    "    \"SELECT \" \\\n",
    "    \"min(purchase_date) as first_purchase_date, \" \\\n",
    "    \"max(purchase_date) as last_purchase_date FROM retail_sales\"\n",
    "    ) \\\n",
    "    .show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "id": "c85bbe07",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "+-------------------+------------------+\n",
      "|first_purchase_date|last_purchase_date|\n",
      "+-------------------+------------------+\n",
      "|         2022-05-15|        2025-04-25|\n",
      "+-------------------+------------------+\n",
      "\n"
     ]
    }
   ],
   "source": [
    "df.select(min(df.purchase_date).alias(\"first_purchase_date\"), max(df.purchase_date).alias(\"last_purchase_date\")) \\\n",
    "    .show()\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "d0b5bfa1",
   "metadata": {},
   "source": [
    "## Aggregations and Grouping"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "e87e9a0d",
   "metadata": {},
   "source": [
    "### What is the total revenue generated from all transactions?"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "id": "b72e6150",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "+-----------+\n",
      "|total_sales|\n",
      "+-----------+\n",
      "|    18618.1|\n",
      "+-----------+\n",
      "\n"
     ]
    }
   ],
   "source": [
    "spark.sql(\"\"\"\n",
    "    SELECT\n",
    "        SUM(purchase_amount) as total_sales\n",
    "    FROM retail_sales\n",
    "\"\"\"\n",
    ").show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "id": "e5561337",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "+-----------+\n",
      "|total_sales|\n",
      "+-----------+\n",
      "|    18618.1|\n",
      "+-----------+\n",
      "\n"
     ]
    }
   ],
   "source": [
    "df.select(sum(df.purchase_amount).alias(\"total_sales\")) \\\n",
    "    .show()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "07380b7d",
   "metadata": {},
   "source": [
    "### Show the total quantity of products sold per category."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "id": "3b219595",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "+----------------+--------------+\n",
      "|product_category|total_quantity|\n",
      "+----------------+--------------+\n",
      "|  Home & Kitchen|            25|\n",
      "|     Electronics|            42|\n",
      "|        Clothing|            40|\n",
      "|           Books|            34|\n",
      "|            Toys|            50|\n",
      "+----------------+--------------+\n",
      "\n"
     ]
    }
   ],
   "source": [
    "spark.sql(\"\"\"\n",
    "    SELECT\n",
    "        product_category,\n",
    "        SUM(quantity) as total_quantity\n",
    "        FROM retail_sales\n",
    "        GROUP BY product_category\n",
    "\"\"\").show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "id": "ac364dfc",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "+----------------+--------------+\n",
      "|product_category|total_quantity|\n",
      "+----------------+--------------+\n",
      "|  Home & Kitchen|            25|\n",
      "|     Electronics|            42|\n",
      "|        Clothing|            40|\n",
      "|           Books|            34|\n",
      "|            Toys|            50|\n",
      "+----------------+--------------+\n",
      "\n"
     ]
    }
   ],
   "source": [
    "df.groupBy(\"product_category\") \\\n",
    "    .sum(\"quantity\") \\\n",
    "    .withColumnRenamed(\"sum(quantity)\", \"total_quantity\") \\\n",
    "    .show()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "21709cca",
   "metadata": {},
   "source": [
    "### Which payment method was used most frequently?"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "id": "fc151613",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "+--------------+--------------------+\n",
      "|payment_method|count_payment_method|\n",
      "+--------------+--------------------+\n",
      "|   Credit Card|                  15|\n",
      "|     Gift Card|                  14|\n",
      "|        PayPal|                  11|\n",
      "|    Debit Card|                  11|\n",
      "|          Cash|                   9|\n",
      "+--------------+--------------------+\n",
      "\n"
     ]
    }
   ],
   "source": [
    "spark.sql(\"\"\"\n",
    "    SELECT\n",
    "        payment_method,\n",
    "        count(payment_method) as count_payment_method\n",
    "    FROM retail_sales\n",
    "        GROUP BY payment_method\n",
    "        ORDER BY count_payment_method DESC\n",
    "\"\"\").show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "id": "2921194b",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "+--------------+--------------------+\n",
      "|payment_method|count_payment_method|\n",
      "+--------------+--------------------+\n",
      "|   Credit Card|                  15|\n",
      "|     Gift Card|                  14|\n",
      "|        PayPal|                  11|\n",
      "|    Debit Card|                  11|\n",
      "|          Cash|                   9|\n",
      "+--------------+--------------------+\n",
      "\n"
     ]
    }
   ],
   "source": [
    "df.groupBy(\"payment_method\") \\\n",
    "    .agg(count(\"payment_method\").alias(\"count_payment_method\")) \\\n",
    "    .orderBy(desc(\"count_payment_method\")) \\\n",
    "    .withColumnRenamed(\"count(payment_method)\", \"count_payment_method\") \\\n",
    "    .show()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "5ee7d809",
   "metadata": {},
   "source": [
    "### What is the average purchase amount for each product category?"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "id": "17584915",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "+----------------+-----------------------+\n",
      "|product_category|average_purchase_amount|\n",
      "+----------------+-----------------------+\n",
      "|  Home & Kitchen|               308.4275|\n",
      "|     Electronics|      277.2583333333334|\n",
      "|        Clothing|      322.4533333333333|\n",
      "|           Books|      308.3781818181819|\n",
      "|            Toys|       327.175294117647|\n",
      "+----------------+-----------------------+\n",
      "\n"
     ]
    }
   ],
   "source": [
    "spark.sql(\n",
    "    \"\"\"\n",
    "    SELECT\n",
    "        product_category,\n",
    "        avg(purchase_amount) as average_purchase_amount\n",
    "    FROM retail_sales\n",
    "        GROUP BY product_category\n",
    "    \"\"\"\n",
    ").show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "id": "86a0cdf4",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "+----------------+-----------------------+\n",
      "|product_category|average_purchase_amount|\n",
      "+----------------+-----------------------+\n",
      "|  Home & Kitchen|               308.4275|\n",
      "|     Electronics|      277.2583333333334|\n",
      "|        Clothing|      322.4533333333333|\n",
      "|           Books|      308.3781818181819|\n",
      "|            Toys|       327.175294117647|\n",
      "+----------------+-----------------------+\n",
      "\n"
     ]
    }
   ],
   "source": [
    "df.groupBy(\"product_category\") \\\n",
    "    .agg(avg(\"purchase_amount\").alias(\"average_purchase_amount\")) \\\n",
    "    .show()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "3b96cf33",
   "metadata": {},
   "source": [
    "### List the top 5 highest value transactions"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "id": "50746f45",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "+--------------------+---------------+\n",
      "|      transaction_id|purchase_amount|\n",
      "+--------------------+---------------+\n",
      "|402d9a4e-7920-443...|         483.87|\n",
      "|3eb312c4-78e0-4de...|         482.71|\n",
      "|3ae6dec4-b804-4b3...|         468.24|\n",
      "|012d0eda-c493-4d4...|         462.16|\n",
      "|33af77a9-6445-468...|         459.28|\n",
      "+--------------------+---------------+\n",
      "\n"
     ]
    }
   ],
   "source": [
    "spark.sql(\n",
    "    \"\"\"\n",
    "    SELECT\n",
    "        transaction_id,\n",
    "        purchase_amount\n",
    "    FROM retail_sales\n",
    "    ORDER BY purchase_amount DESC\n",
    "    LIMIT 5\n",
    "    \"\"\"\n",
    ").show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "id": "0407511b",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "+--------------------+---------------+\n",
      "|      transaction_id|purchase_amount|\n",
      "+--------------------+---------------+\n",
      "|402d9a4e-7920-443...|         483.87|\n",
      "|3eb312c4-78e0-4de...|         482.71|\n",
      "|3ae6dec4-b804-4b3...|         468.24|\n",
      "|012d0eda-c493-4d4...|         462.16|\n",
      "|33af77a9-6445-468...|         459.28|\n",
      "+--------------------+---------------+\n",
      "\n"
     ]
    }
   ],
   "source": [
    "df.select(\"transaction_id\", \"purchase_amount\") \\\n",
    "    .orderBy(desc(\"purchase_amount\")) \\\n",
    "    .limit(5) \\\n",
    "    .show()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "74a0574d",
   "metadata": {},
   "source": [
    "## Insights"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "8be6e195",
   "metadata": {},
   "source": [
    "### Which customer made the highest total purchase amount?"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "id": "7e6e7c2a",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "+-----------+-------------+---------------------+\n",
      "|customer_id|customer_name|total_purchase_amount|\n",
      "+-----------+-------------+---------------------+\n",
      "|       7674|Kent Marshall|               483.87|\n",
      "+-----------+-------------+---------------------+\n",
      "\n"
     ]
    }
   ],
   "source": [
    "spark.sql(\n",
    "    \"\"\"\n",
    "    SELECT\n",
    "        customer_id,\n",
    "        customer_name,\n",
    "        SUM(purchase_amount) as total_purchase_amount\n",
    "    FROM retail_sales\n",
    "    GROUP BY customer_id, customer_name\n",
    "    ORDER BY SUM(purchase_amount) DESC\n",
    "    LIMIT 1\n",
    "    \"\"\"\n",
    ").show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "id": "121fd6d4",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "+-----------+-------------+---------------------+\n",
      "|customer_id|customer_name|total_purchase_amount|\n",
      "+-----------+-------------+---------------------+\n",
      "|       7674|Kent Marshall|               483.87|\n",
      "+-----------+-------------+---------------------+\n",
      "\n"
     ]
    }
   ],
   "source": [
    "df.groupBy(\"customer_id\", \"customer_name\") \\\n",
    "    .agg(sum(\"purchase_amount\").alias(\"total_purchase_amount\")) \\\n",
    "    .orderBy(desc(sum(\"purchase_amount\"))) \\\n",
    "    .limit(1) \\\n",
    "    .show()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "0955df18",
   "metadata": {},
   "source": [
    "### What is the average purchase amount by payment method?"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "id": "9f725489",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "+--------------+-----------------------+\n",
      "|payment_method|average_purchase_amount|\n",
      "+--------------+-----------------------+\n",
      "|   Credit Card|                280.368|\n",
      "|        PayPal|      276.4827272727273|\n",
      "|          Cash|      402.2755555555555|\n",
      "|     Gift Card|      276.6235714285715|\n",
      "|    Debit Card|      352.5509090909091|\n",
      "+--------------+-----------------------+\n",
      "\n"
     ]
    }
   ],
   "source": [
    "spark.sql(\n",
    "    \"\"\"\n",
    "    SELECT\n",
    "        payment_method,\n",
    "        avg(purchase_amount) as average_purchase_amount\n",
    "    FROM retail_sales\n",
    "    GROUP BY payment_method\n",
    "    \"\"\"\n",
    ").show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "id": "ee1e7bd0",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "+--------------+-----------------------+\n",
      "|payment_method|average_purchase_amount|\n",
      "+--------------+-----------------------+\n",
      "|   Credit Card|                280.368|\n",
      "|        PayPal|      276.4827272727273|\n",
      "|          Cash|      402.2755555555555|\n",
      "|     Gift Card|      276.6235714285715|\n",
      "|    Debit Card|      352.5509090909091|\n",
      "+--------------+-----------------------+\n",
      "\n"
     ]
    }
   ],
   "source": [
    "df.groupBy(\"payment_method\") \\\n",
    "    .agg(avg(\"purchase_amount\").alias(\"average_purchase_amount\")) \\\n",
    "    .show()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "378143ba",
   "metadata": {},
   "source": [
    "### For each year, how many transactions took place?"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "id": "47b33215",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "root\n",
      " |-- transaction_id: string (nullable = true)\n",
      " |-- customer_id: integer (nullable = true)\n",
      " |-- customer_name: string (nullable = true)\n",
      " |-- product_category: string (nullable = true)\n",
      " |-- purchase_amount: double (nullable = true)\n",
      " |-- quantity: integer (nullable = true)\n",
      " |-- payment_method: string (nullable = true)\n",
      " |-- purchase_date: date (nullable = true)\n",
      "\n"
     ]
    }
   ],
   "source": [
    "df.printSchema()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "id": "ab3fa8da",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "+-------------+------------------+\n",
      "|purchase_year|total_transactions|\n",
      "+-------------+------------------+\n",
      "|         2025|                 8|\n",
      "|         2023|                20|\n",
      "|         2022|                12|\n",
      "|         2024|                20|\n",
      "+-------------+------------------+\n",
      "\n"
     ]
    }
   ],
   "source": [
    "spark.sql(\n",
    "    \"\"\"\n",
    "    SELECT\n",
    "        year(purchase_date) as purchase_year,\n",
    "        count(transaction_id) as total_transactions\n",
    "    FROM retail_sales\n",
    "    GROUP BY year(purchase_date)\n",
    "    \"\"\"\n",
    ").show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "id": "1462c4d6",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "+-------------+------------------+\n",
      "|purchase_date|total_transactions|\n",
      "+-------------+------------------+\n",
      "|         2025|                 8|\n",
      "|         2023|                20|\n",
      "|         2022|                12|\n",
      "|         2024|                20|\n",
      "+-------------+------------------+\n",
      "\n"
     ]
    }
   ],
   "source": [
    "df.groupBy(year(\"purchase_date\").alias(\"purchase_date\")) \\\n",
    "    .agg(count(\"transaction_id\").alias(\"total_transactions\")) \\\n",
    "    .show()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "d5490266",
   "metadata": {},
   "source": [
    "### Add a new column called total_amount = purchase_amount * quantity. Show the updated DataFrame."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "id": "af572dff",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "+------------------+\n",
      "|      total_amount|\n",
      "+------------------+\n",
      "|           1478.56|\n",
      "|             57.64|\n",
      "|            367.36|\n",
      "|            404.03|\n",
      "|           1892.55|\n",
      "|            468.24|\n",
      "|             51.25|\n",
      "|            914.25|\n",
      "|            452.45|\n",
      "|           1530.88|\n",
      "|            798.84|\n",
      "|            180.83|\n",
      "|            1214.1|\n",
      "|           1635.16|\n",
      "|            1131.9|\n",
      "|            284.48|\n",
      "|             199.6|\n",
      "| 890.9100000000001|\n",
      "|           1074.84|\n",
      "|1131.4499999999998|\n",
      "+------------------+\n",
      "only showing top 20 rows\n",
      "\n"
     ]
    }
   ],
   "source": [
    "spark.sql(\n",
    "    \"\"\"\n",
    "    SELECT\n",
    "        purchase_amount * quantity AS total_amount\n",
    "    FROM retail_sales\n",
    "    \"\"\"\n",
    ").show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "id": "423663cd",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "+------------------+\n",
      "|      total_amount|\n",
      "+------------------+\n",
      "|           1478.56|\n",
      "|             57.64|\n",
      "|            367.36|\n",
      "|            404.03|\n",
      "|           1892.55|\n",
      "|            468.24|\n",
      "|             51.25|\n",
      "|            914.25|\n",
      "|            452.45|\n",
      "|           1530.88|\n",
      "|            798.84|\n",
      "|            180.83|\n",
      "|            1214.1|\n",
      "|           1635.16|\n",
      "|            1131.9|\n",
      "|            284.48|\n",
      "|             199.6|\n",
      "| 890.9100000000001|\n",
      "|           1074.84|\n",
      "|1131.4499999999998|\n",
      "+------------------+\n",
      "only showing top 20 rows\n",
      "\n"
     ]
    }
   ],
   "source": [
    "df2 = df.withColumn(\"total_amount\", col(\"purchase_amount\") * col(\"quantity\"))\n",
    "df2.select(\"total_amount\").show()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "b8495214",
   "metadata": {},
   "source": [
    "### What is the average total_amount per product category?"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "id": "25207ee4",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "+----------------+--------------------+\n",
      "|product_category|average_total_amount|\n",
      "+----------------+--------------------+\n",
      "|  Home & Kitchen|  1069.8174999999999|\n",
      "|     Electronics|   901.5125000000002|\n",
      "|        Clothing|             1060.49|\n",
      "|           Books|   959.6081818181821|\n",
      "|            Toys|   869.5723529411765|\n",
      "+----------------+--------------------+\n",
      "\n"
     ]
    }
   ],
   "source": [
    "df2.groupBy(\"product_category\") \\\n",
    "    .agg(avg(\"total_amount\").alias(\"average_total_amount\")) \\\n",
    "    .show()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "64ef36fc",
   "metadata": {},
   "source": [
    "## Bonus"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "28eb1235",
   "metadata": {},
   "source": [
    "### Which day of the week has the highest number of purchases?"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 33,
   "id": "95e7088c",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "+------------+------------------+\n",
      "|purchase_day|total_transactions|\n",
      "+------------+------------------+\n",
      "|           1|                12|\n",
      "|           2|                 9|\n",
      "|           3|                 7|\n",
      "|           4|                 5|\n",
      "|           5|                 9|\n",
      "|           6|                13|\n",
      "|           7|                 5|\n",
      "+------------+------------------+\n",
      "\n"
     ]
    }
   ],
   "source": [
    "spark.sql(\n",
    "    \"\"\"\n",
    "    SELECT\n",
    "        dayofweek(purchase_date) as purchase_day,\n",
    "        count(transaction_id) as total_transactions\n",
    "    FROM retail_sales\n",
    "    GROUP BY dayofweek(purchase_date)\n",
    "    ORDER BY purchase_day\n",
    "    \"\"\"\n",
    ").show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 34,
   "id": "cc250be1",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "+------------+------------------+\n",
      "|purchase_day|total_transactions|\n",
      "+------------+------------------+\n",
      "|           1|                12|\n",
      "|           2|                 9|\n",
      "|           3|                 7|\n",
      "|           4|                 5|\n",
      "|           5|                 9|\n",
      "|           6|                13|\n",
      "|           7|                 5|\n",
      "+------------+------------------+\n",
      "\n"
     ]
    }
   ],
   "source": [
    "df.groupBy(dayofweek(\"purchase_date\").alias(\"purchase_day\")) \\\n",
    "    .agg(count(\"transaction_id\").alias(\"total_transactions\")) \\\n",
    "    .orderBy(\"purchase_day\") \\\n",
    "    .show()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "8e48cebf",
   "metadata": {},
   "source": [
    "### Create a temporary view and write a SQL query to find the most popular product category for each payment method."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 35,
   "id": "5b8e7f86",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "+----------------+--------------+------------------+\n",
      "|product_category|payment_method|total_transactions|\n",
      "+----------------+--------------+------------------+\n",
      "|     Electronics|          Cash|                 3|\n",
      "|        Clothing|   Credit Card|                 5|\n",
      "|            Toys|    Debit Card|                 4|\n",
      "|            Toys|     Gift Card|                 4|\n",
      "|            Toys|        PayPal|                 4|\n",
      "+----------------+--------------+------------------+\n",
      "\n"
     ]
    }
   ],
   "source": [
    "spark.sql(\n",
    "    \"\"\"\n",
    "    SELECT\n",
    "        product_category,\n",
    "        payment_method,\n",
    "        total_transactions\n",
    "    FROM (\n",
    "        SELECT\n",
    "            payment_method,\n",
    "            product_category,\n",
    "            count(*) as total_transactions,\n",
    "            row_number() over (partition by payment_method order by count(*) desc) as rank\n",
    "        FROM retail_sales\n",
    "        GROUP BY payment_method, product_category\n",
    "        ) ranked\n",
    "    WHERE rank = 1\n",
    "    \"\"\"\n",
    ").show()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "9ff068ab",
   "metadata": {},
   "source": [
    "### Filter and display all purchases made using PayPal over $200."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 36,
   "id": "3096c63f",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "+----------------+--------------+---------------+\n",
      "|product_category|payment_method|purchase_amount|\n",
      "+----------------+--------------+---------------+\n",
      "|  Home & Kitchen|        PayPal|         378.51|\n",
      "|           Books|        PayPal|         284.48|\n",
      "|     Electronics|        PayPal|         342.98|\n",
      "|  Home & Kitchen|        PayPal|         206.03|\n",
      "|            Toys|        PayPal|         224.91|\n",
      "|            Toys|        PayPal|         459.28|\n",
      "|        Clothing|        PayPal|         427.28|\n",
      "|           Books|        PayPal|         341.09|\n",
      "+----------------+--------------+---------------+\n",
      "\n"
     ]
    }
   ],
   "source": [
    "spark.sql(\n",
    "    \"\"\"\n",
    "    SELECT\n",
    "        product_category,\n",
    "        payment_method,\n",
    "        purchase_amount\n",
    "    FROM retail_sales\n",
    "    WHERE payment_method = \"PayPal\" and purchase_amount > 200\n",
    "    \"\"\"\n",
    ").show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 37,
   "id": "dbb64058",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "+----------------+--------------+---------------+\n",
      "|product_category|payment_method|purchase_amount|\n",
      "+----------------+--------------+---------------+\n",
      "|  Home & Kitchen|        PayPal|         378.51|\n",
      "|           Books|        PayPal|         284.48|\n",
      "|     Electronics|        PayPal|         342.98|\n",
      "|  Home & Kitchen|        PayPal|         206.03|\n",
      "|            Toys|        PayPal|         224.91|\n",
      "|            Toys|        PayPal|         459.28|\n",
      "|        Clothing|        PayPal|         427.28|\n",
      "|           Books|        PayPal|         341.09|\n",
      "+----------------+--------------+---------------+\n",
      "\n"
     ]
    }
   ],
   "source": [
    "df.select(\"product_category\", \"payment_method\", \"purchase_amount\") \\\n",
    "    .filter((col(\"payment_method\") == \"PayPal\") & (col(\"purchase_amount\") > 200)) \\\n",
    "    .show()"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "venv",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.6"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
